"""
–ú–æ–¥—É–ª—å —Ä–∞—Å—á—ë—Ç–∞ –º–µ—Ç—Ä–∏–∫ v2.0
–†–∞–∑–º–µ—Ä –Ω–∏—à–∏, –∫–æ–Ω–∫—É—Ä–µ–Ω—Ü–∏—è, —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å
"""

from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from wordstat_client import WordstatClient
from config import (
    SIZE_THRESHOLDS, SIZE_LABELS, SIZE_INDEX_MAX,
    COMPETITION_WEIGHTS, COMPETITION_THRESHOLDS, COMPETITION_LABELS,
    BRAND_PATTERNS, VERDICT_LABELS, VERDICT_RULES
)


TOKEN = "y0__xCHu4rZARjd0Dogyfj_7RQJLwxI8zao8Pru2PA2l5w2HjR6dA"


class MetricsCalculator:
    """–ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä –º–µ—Ç—Ä–∏–∫ –Ω–∏—à–∏"""
    
    def __init__(self):
        self.client = WordstatClient(TOKEN)
        self._regions_cache = None
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # –†–ï–ì–ò–û–ù–ê–õ–¨–ù–´–ô –ö–û–≠–§–§–ò–¶–ò–ï–ù–¢
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    def get_region_coefficient(self, phrase: str, region_id: int) -> Tuple[float, Dict]:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–ª—è —Ñ—Ä–∞–∑—ã.
        
        –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –Ω–∞—Å–∫–æ–ª—å–∫–æ —Å–ø—Ä–æ—Å –≤ —Ä–µ–≥–∏–æ–Ω–µ –≤—ã—à–µ/–Ω–∏–∂–µ 
        —Å—Ä–µ–¥–Ω–µ–≥–æ –ø–æ –†–æ—Å—Å–∏–∏.
        
        Returns:
            (coefficient, details)
            coefficient: 1.0 = —Å—Ä–µ–¥–Ω–∏–π, >1 = –≤—ã—à–µ —Å—Ä–µ–¥–Ω–µ–≥–æ, <1 = –Ω–∏–∂–µ
        """
        try:
            result = self.client.get_regions(phrase)
            regions = result.get('regions', [])
            
            if not regions:
                return 1.0, {"error": "no_data"}
            
            # –ù–∞—Ö–æ–¥–∏–º –¥–∞–Ω–Ω—ã–µ –ø–æ –∑–∞–ø—Ä–æ—à–µ–Ω–Ω–æ–º—É —Ä–µ–≥–∏–æ–Ω—É –∏ –ø–æ –†–æ—Å—Å–∏–∏ (225)
            total_count = sum(r.get('count', 0) for r in regions)
            russia_data = None
            region_data = None
            
            for r in regions:
                if r.get('regionId') == 225:
                    russia_data = r
                if r.get('regionId') == region_id:
                    region_data = r
            
            # –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –ø–æ –≤—Å–µ–π –†–æ—Å—Å–∏–∏ ‚Äî –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç 1.0
            if region_id == 225:
                return 1.0, {
                    "region_name": "–†–æ—Å—Å–∏—è",
                    "region_count": russia_data.get('count', 0) if russia_data else total_count,
                    "total_count": total_count,
                    "coefficient": 1.0
                }
            
            if not region_data:
                return 1.0, {"error": "region_not_found", "region_id": region_id}
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç
            # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –¥–æ–ª—é —Ä–µ–≥–∏–æ–Ω–∞ —Å –µ–≥–æ "–Ω–æ—Ä–º–∞–ª—å–Ω–æ–π" –¥–æ–ª–µ–π –≤ –æ–±—â–µ–º —Ç—Ä–∞—Ñ–∏–∫–µ
            region_share = region_data.get('share', 0)
            affinity_index = region_data.get('affinityIndex', 100)
            
            # affinityIndex –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∏–Ω—Ç–µ—Ä–µ—Å –∫ —Ç–µ–º–µ –≤ —Ä–µ–≥–∏–æ–Ω–µ
            # 100 = —Å—Ä–µ–¥–Ω–∏–π, >100 = –≤—ã—à–µ —Å—Ä–µ–¥–Ω–µ–≥–æ
            coefficient = affinity_index / 100.0
            
            return coefficient, {
                "region_id": region_id,
                "region_count": region_data.get('count', 0),
                "region_share": round(region_share * 100, 2),
                "affinity_index": round(affinity_index, 1),
                "coefficient": round(coefficient, 2),
                "total_count": total_count
            }
            
        except Exception as e:
            return 1.0, {"error": str(e)}
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # –°–ï–ó–û–ù–ù–´–ô –ö–û–≠–§–§–ò–¶–ò–ï–ù–¢
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    def get_seasonality_coefficient(self, phrase: str, region_id: int = 225) -> Tuple[float, Dict]:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å–µ–∑–æ–Ω–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç.
        
        –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç = —Ç–µ–∫—É—â–∏–π –º–µ—Å—è—Ü / —Å—Ä–µ–¥–Ω–µ–µ –∑–∞ –≥–æ–¥
        >1 = —Å–µ–π—á–∞—Å —Å–ø—Ä–æ—Å –≤—ã—à–µ —Å—Ä–µ–¥–Ω–µ–≥–æ (—Ö–æ—Ä–æ—à–µ–µ –≤—Ä–µ–º—è)
        <1 = —Å–µ–π—á–∞—Å —Å–ø—Ä–æ—Å –Ω–∏–∂–µ —Å—Ä–µ–¥–Ω–µ–≥–æ
        
        Returns:
            (coefficient, details)
        """
        try:
            # –ü–µ—Ä–∏–æ–¥: –ø–æ—Å–ª–µ–¥–Ω–∏–µ 12 –º–µ—Å—è—Ü–µ–≤
            now = datetime.now()
            
            # to_date = –ø–æ—Å–ª–µ–¥–Ω–∏–π –¥–µ–Ω—å –ø—Ä–æ—à–ª–æ–≥–æ –º–µ—Å—è—Ü–∞
            to_dt = now.replace(day=1) - timedelta(days=1)
            to_date = to_dt.strftime("%Y-%m-%d")
            
            # from_date = –ø–µ—Ä–≤—ã–π –¥–µ–Ω—å 12 –º–µ—Å—è—Ü–µ–≤ –Ω–∞–∑–∞–¥
            from_dt = to_dt.replace(day=1)
            for _ in range(11):
                from_dt = (from_dt - timedelta(days=1)).replace(day=1)
            from_date = from_dt.strftime("%Y-%m-%d")
            
            result = self.client.get_dynamics(
                phrase,
                period="monthly",
                from_date=from_date,
                to_date=to_date,
                regions=[region_id] if region_id != 225 else None
            )
            
            dynamics = result.get('dynamics', [])
            
            if not dynamics:
                return 1.0, {"error": "no_data"}
            
            counts = [d.get('count', 0) for d in dynamics]
            average = sum(counts) / len(counts) if counts else 1
            current = counts[-1] if counts else 0
            
            # –ù–∞—Ö–æ–¥–∏–º –ø–∏–∫–∏ –∏ —Å–ø–∞–¥—ã
            max_month = max(dynamics, key=lambda x: x.get('count', 0))
            min_month = min(dynamics, key=lambda x: x.get('count', 0))
            
            coefficient = current / average if average > 0 else 1.0
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç—Ä–µ–Ω–¥ (—Ä–∞—Å—Ç—ë—Ç/–ø–∞–¥–∞–µ—Ç)
            if len(counts) >= 3:
                recent_avg = sum(counts[-3:]) / 3
                earlier_avg = sum(counts[:3]) / 3
                trend = "growing" if recent_avg > earlier_avg * 1.1 else \
                        "declining" if recent_avg < earlier_avg * 0.9 else "stable"
            else:
                trend = "unknown"
            
            # –†–æ—Å—Ç –∑–∞ –≥–æ–¥ (—Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –º–µ—Å—è—Ü —Å –ø–µ—Ä–≤—ã–º)
            if len(counts) >= 2 and counts[0] > 0:
                yearly_growth = round(((counts[-1] / counts[0]) - 1) * 100, 1)
            else:
                yearly_growth = 0.0
            
            return round(coefficient, 2), {
                "current_month": current,
                "average_month": round(average),
                "coefficient": round(coefficient, 2),
                "peak_month": max_month.get('date', ''),
                "peak_count": max_month.get('count', 0),
                "low_month": min_month.get('date', ''),
                "low_count": min_month.get('count', 0),
                "trend": trend,
                "yearly_growth": yearly_growth,
                "dynamics": dynamics
            }
            
        except Exception as e:
            return 1.0, {"error": str(e)}
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # –†–ê–ó–ú–ï–† –ù–ò–®–ò
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    def calculate_size_metrics(
        self, 
        total_count: int,
        region_coef: float = 1.0,
        season_coef: float = 1.0
    ) -> Dict:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ —Ä–∞–∑–º–µ—Ä–∞ –Ω–∏—à–∏.
        
        Args:
            total_count: —Å—É–º–º–∞ —á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç–µ–π –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
            region_coef: —Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç (–∏–∑ get_region_coefficient)
            season_coef: —Å–µ–∑–æ–Ω–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç (–∏–∑ get_seasonality_coefficient)
        
        Returns:
            {
                "raw_count": –∏—Å—Ö–æ–¥–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ,
                "normalized_count": –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ,
                "size_index": 0-100,
                "size_label": "–°—Ä–µ–¥–Ω—è—è",
                "size_icon": "üìä"
            }
        """
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å —É—á—ë—Ç–æ–º —Ä–µ–≥–∏–æ–Ω–∞ –∏ —Å–µ–∑–æ–Ω–∞
        # –ï—Å–ª–∏ —Ä–µ–≥–∏–æ–Ω < 1 (–Ω–∏–∑–∫–∏–π affinity), —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –æ—Ü–µ–Ω–∫—É
        # –ï—Å–ª–∏ —Å–µ–∑–æ–Ω < 1 (–Ω–∏–∑–∫–∏–π —Å–µ–∑–æ–Ω), —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –æ—Ü–µ–Ω–∫—É
        normalized = total_count / region_coef / season_coef if region_coef > 0 and season_coef > 0 else total_count
        
        # –ò–Ω–¥–µ–∫—Å 0-100
        size_index = min(100, (normalized / SIZE_INDEX_MAX) * 100)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é
        if normalized < SIZE_THRESHOLDS["micro"]:
            size_key = "micro"
        elif normalized < SIZE_THRESHOLDS["small"]:
            size_key = "small"
        elif normalized < SIZE_THRESHOLDS["medium"]:
            size_key = "medium"
        elif normalized < SIZE_THRESHOLDS["large"]:
            size_key = "large"
        else:
            size_key = "huge"
        
        label, icon = SIZE_LABELS[size_key]
        
        return {
            "raw_count": total_count,
            "normalized_count": round(normalized),
            "size_index": round(size_index, 1),
            "size_key": size_key,
            "size_label": label,
            "size_icon": icon,
            "region_coefficient": region_coef,
            "season_coefficient": season_coef
        }
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # –ö–û–ù–ö–£–†–ï–ù–¶–ò–Ø
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    def calculate_brand_share(self, queries: List[Dict]) -> Tuple[float, List[str]]:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –¥–æ–ª—é –±—Ä–µ–Ω–¥–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"""
        if not queries:
            return 0.0, []
        
        total_count = sum(q.get('count', 0) for q in queries)
        brand_count = 0
        found_brands = set()
        
        for q in queries:
            phrase_lower = q.get('phrase', '').lower()
            for brand in BRAND_PATTERNS:
                if brand in phrase_lower:
                    brand_count += q.get('count', 0)
                    found_brands.add(brand)
                    break
        
        share = (brand_count / total_count * 100) if total_count > 0 else 0
        return round(share, 1), list(found_brands)
    
    def calculate_competition_metrics(
        self,
        queries: List[Dict],
        clusters: List[Dict],
        mp_share: float = 0.0,
        geo_share: float = 0.0
    ) -> Dict:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ü–∏–∏.
        
        Args:
            queries: —Å–ø–∏—Å–æ–∫ –∑–∞–ø—Ä–æ—Å–æ–≤ —Å count
            clusters: —Å–ø–∏—Å–æ–∫ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ —Å share
            mp_share: –¥–æ–ª—è –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å-–∑–∞–ø—Ä–æ—Å–æ–≤ (—É–∂–µ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–∞)
            geo_share: –¥–æ–ª—è –≥–µ–æ-–∑–∞–ø—Ä–æ—Å–æ–≤
        """
        if not queries or not clusters:
            return {
                "competition_index": 50,
                "competition_label": "–°—Ä–µ–¥–Ω—è—è",
                "competition_icon": "üü°",
                "factors": {}
            }
        
        total_count = sum(q.get('count', 0) for q in queries)
        
        # 1. –ö–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è –≤ —Ç–æ–ø-3 –∫–ª–∞—Å—Ç–µ—Ä–∞—Ö
        top3_share = sum(c.get('share', 0) for c in clusters[:3])
        
        # 2. –î–æ–ª—è –±—Ä–µ–Ω–¥–æ–≤
        brand_share, found_brands = self.calculate_brand_share(queries)
        
        # 3. –ü–ª–æ—Ç–Ω–æ—Å—Ç—å (–∑–∞–ø—Ä–æ—Å–æ–≤ –Ω–∞ –∫–ª–∞—Å—Ç–µ—Ä)
        density = total_count / len(clusters) if clusters else 0
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å –∫–æ–Ω–∫—É—Ä–µ–Ω—Ü–∏–∏
        # top3_share —É–∂–µ –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö (0-100)
        competition_index = (
            top3_share * COMPETITION_WEIGHTS["top3_concentration"] +
            brand_share * COMPETITION_WEIGHTS["brand_share"] +
            mp_share * COMPETITION_WEIGHTS["mp_share"]
        )
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é
        if competition_index < COMPETITION_THRESHOLDS["low"]:
            comp_key = "low"
        elif competition_index < COMPETITION_THRESHOLDS["medium"]:
            comp_key = "medium"
        elif competition_index < COMPETITION_THRESHOLDS["high"]:
            comp_key = "high"
        else:
            comp_key = "very_high"
        
        label, icon = COMPETITION_LABELS[comp_key]
        
        return {
            "competition_index": round(competition_index, 1),
            "competition_key": comp_key,
            "competition_label": label,
            "competition_icon": icon,
            "factors": {
                "top3_concentration": round(top3_share, 1),
                "brand_share": brand_share,
                "mp_share": round(mp_share, 1),
                "density": round(density),
                "found_brands": found_brands[:10]  # —Ç–æ–ø-10 –±—Ä–µ–Ω–¥–æ–≤
            }
        }
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # –í–ï–†–î–ò–ö–¢
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    def determine_verdict(
        self,
        size_index: float,
        competition_index: float,
        queries_count: int
    ) -> Dict:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –≤–µ—Ä–¥–∏–∫—Ç –ø–æ –Ω–∏—à–µ.
        
        Returns:
            {"verdict": "conditional", "verdict_label": "...", "verdict_icon": "‚ö†Ô∏è"}
        """
        # –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö
        if queries_count < 50:
            return {
                "verdict": "uncertain",
                "verdict_label": VERDICT_LABELS["uncertain"][0],
                "verdict_icon": VERDICT_LABELS["uncertain"][1],
                "reason": "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"
            }
        
        rules = VERDICT_RULES
        
        # –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è
        if size_index >= rules["recommended"]["min_size"] and \
           competition_index <= rules["recommended"]["max_competition"]:
            return {
                "verdict": "recommended",
                "verdict_label": VERDICT_LABELS["recommended"][0],
                "verdict_icon": VERDICT_LABELS["recommended"][1],
                "reason": "–î–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∏ —É–º–µ—Ä–µ–Ω–Ω–∞—è –∫–æ–Ω–∫—É—Ä–µ–Ω—Ü–∏—è"
            }
        
        # –ù–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è
        if size_index <= rules["not_recommended"]["max_size"] or \
           competition_index >= rules["not_recommended"]["min_competition"]:
            return {
                "verdict": "not_recommended",
                "verdict_label": VERDICT_LABELS["not_recommended"][0],
                "verdict_icon": VERDICT_LABELS["not_recommended"][1],
                "reason": "–°–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–π —Ä—ã–Ω–æ–∫ –∏–ª–∏ –≤—ã—Å–æ–∫–∞—è –∫–æ–Ω–∫—É—Ä–µ–Ω—Ü–∏—è"
            }
        
        # –° –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏ (–≤—Å—ë –æ—Å—Ç–∞–ª—å–Ω–æ–µ)
        return {
            "verdict": "conditional",
            "verdict_label": VERDICT_LABELS["conditional"][0],
            "verdict_icon": VERDICT_LABELS["conditional"][1],
            "reason": "–ï—Å—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏, –Ω–æ —Ç—Ä–µ–±—É–µ—Ç—Å—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è"
        }


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –¢–ï–°–¢
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

if __name__ == "__main__":
    import json
    
    calc = MetricsCalculator()
    
    phrase = "–∫—É–ø–∏—Ç—å –∫—Ä–æ—Å—Å–æ–≤–∫–∏"
    region = 213  # –ú–æ—Å–∫–≤–∞
    
    print(f"=== –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è '{phrase}' (—Ä–µ–≥–∏–æ–Ω {region}) ===\n")
    
    # 1. –†–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç
    region_coef, region_details = calc.get_region_coefficient(phrase, region)
    print(f"–†–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã–π –∫–æ—ç—Ñ: {region_coef}")
    print(f"  –î–µ—Ç–∞–ª–∏: {json.dumps(region_details, ensure_ascii=False)}\n")
    
    # 2. –°–µ–∑–æ–Ω–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç
    season_coef, season_details = calc.get_seasonality_coefficient(phrase, region)
    print(f"–°–µ–∑–æ–Ω–Ω—ã–π –∫–æ—ç—Ñ: {season_coef}")
    print(f"  –¢–µ–∫—É—â–∏–π –º–µ—Å—è—Ü: {season_details.get('current_month', 0):,}")
    print(f"  –°—Ä–µ–¥–Ω–µ–µ: {season_details.get('average_month', 0):,}")
    print(f"  –¢—Ä–µ–Ω–¥: {season_details.get('trend', '?')}\n")
    
    # 3. –†–∞–∑–º–µ—Ä –Ω–∏—à–∏ (—Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ)
    test_total = 139_000
    size_metrics = calc.calculate_size_metrics(test_total, region_coef, season_coef)
    print(f"–†–∞–∑–º–µ—Ä –Ω–∏—à–∏:")
    print(f"  Raw: {size_metrics['raw_count']:,}")
    print(f"  Normalized: {size_metrics['normalized_count']:,}")
    print(f"  Index: {size_metrics['size_index']}/100")
    print(f"  Label: {size_metrics['size_icon']} {size_metrics['size_label']}\n")
    
    # 4. –ö–æ–Ω–∫—É—Ä–µ–Ω—Ü–∏—è (—Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ)
    test_queries = [{"phrase": "nike –∫—Ä–æ—Å—Å–æ–≤–∫–∏", "count": 1000}, {"phrase": "–∫—Ä–æ—Å—Å–æ–≤–∫–∏", "count": 5000}]
    test_clusters = [{"name": "test", "share": 40}]
    comp_metrics = calc.calculate_competition_metrics(test_queries, test_clusters, mp_share=3.0)
    print(f"–ö–æ–Ω–∫—É—Ä–µ–Ω—Ü–∏—è:")
    print(f"  Index: {comp_metrics['competition_index']}/100")
    print(f"  Label: {comp_metrics['competition_icon']} {comp_metrics['competition_label']}")
    print(f"  –ë—Ä–µ–Ω–¥—ã: {comp_metrics['factors']['found_brands']}\n")
    
    # 5. –í–µ—Ä–¥–∏–∫—Ç
    verdict = calc.determine_verdict(
        size_metrics['size_index'],
        comp_metrics['competition_index'],
        len(test_queries)
    )
    print(f"–í–µ—Ä–¥–∏–∫—Ç: {verdict['verdict_icon']} {verdict['verdict_label']}")
    print(f"  –ü—Ä–∏—á–∏–Ω–∞: {verdict['reason']}")
