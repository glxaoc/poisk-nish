"""
ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€ Ğ½Ğ¸ÑˆĞ¸ v2.0
Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸, ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ñ‹ Ğ¸ Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·
"""

from typing import Dict, List
from metrics import MetricsCalculator
from database import get_all_queries
from clusterer import clusterize


def analyze_niche_v2(phrase: str, region: int = 225) -> Dict:
    """
    ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ½Ğ¸ÑˆĞ¸ v2.0
    
    Returns:
        {
            "phrase": str,
            "region": int,
            "metrics": {...},       # size, competition, etc.
            "seasonality": {...},   # Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸ĞºĞ°, Ñ‚Ñ€ĞµĞ½Ğ´
            "clusters": [...],      # ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ñ‹ Ñ Ğ´Ğ¾Ğ»ÑĞ¼Ğ¸
            "verdict": {...},       # Ğ¿Ñ€ĞµĞ´Ğ²Ğ°Ñ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ²ĞµÑ€Ğ´Ğ¸ĞºÑ‚
            "insights": [...],      # Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ğµ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ñ‹
        }
    """
    calc = MetricsCalculator()
    
    # 1. ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ ÑĞ¾Ğ±Ñ€Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¸Ğ· Ğ‘Ğ”
    queries = get_all_queries(region)
    if not queries:
        return {"error": "no_data", "phrase": phrase}
    
    total_count = sum(q.get('count', 0) for q in queries)
    
    # 2. ĞšĞ»Ğ°ÑÑ‚ĞµÑ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
    cluster_result = clusterize(queries, phrase)
    clusters = cluster_result.get('clusters', [])
    
    # Ğ¡Ñ‡Ğ¸Ñ‚Ğ°ĞµĞ¼ Ğ´Ğ¾Ğ»Ğ¸ Ğ³ĞµĞ¾ Ğ¸ Ğ¼Ğ°Ñ€ĞºĞµÑ‚Ğ¿Ğ»ĞµĞ¹ÑĞ¾Ğ² Ğ¸Ğ· ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ¾Ğ²
    geo_share = 0
    mp_share = 0
    for c in clusters:
        if c.get('name') == 'Ğ“ĞµĞ¾Ğ³Ñ€Ğ°Ñ„Ğ¸Ñ':
            geo_share = c.get('share', 0)
        elif c.get('name') == 'ĞœĞ°Ñ€ĞºĞµÑ‚Ğ¿Ğ»ĞµĞ¹ÑÑ‹':
            mp_share = c.get('share', 0)
    
    # 3. Ğ ĞµĞ³Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ĞºĞ¾ÑÑ„Ñ„Ğ¸Ñ†Ğ¸ĞµĞ½Ñ‚
    region_coef, region_details = calc.get_region_coefficient(phrase, region)
    
    # 4. Ğ¡ĞµĞ·Ğ¾Ğ½Ğ½Ñ‹Ğ¹ ĞºĞ¾ÑÑ„Ñ„Ğ¸Ñ†Ğ¸ĞµĞ½Ñ‚
    season_coef, season_details = calc.get_seasonality_coefficient(phrase, region)
    
    # 5. Ğ Ğ°Ğ·Ğ¼ĞµÑ€ Ğ½Ğ¸ÑˆĞ¸
    size_metrics = calc.calculate_size_metrics(total_count, region_coef, season_coef)
    
    # 6. ĞšĞ¾Ğ½ĞºÑƒÑ€ĞµĞ½Ñ†Ğ¸Ñ
    comp_metrics = calc.calculate_competition_metrics(
        queries, clusters, mp_share=mp_share, geo_share=geo_share
    )
    
    # 7. ĞŸÑ€ĞµĞ´Ğ²Ğ°Ñ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ²ĞµÑ€Ğ´Ğ¸ĞºÑ‚
    verdict = calc.determine_verdict(
        size_metrics['size_index'],
        comp_metrics['competition_index'],
        len(queries)
    )
    
    # 8. Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¸Ğ½ÑĞ°Ğ¹Ñ‚Ñ‹
    insights = generate_insights_v2(
        size_metrics, comp_metrics, season_details, 
        clusters, geo_share, mp_share
    )
    
    return {
        "phrase": phrase,
        "region": region,
        "total_count": total_count,
        "total_queries": len(queries),
        "clusters_count": len(clusters),
        
        # ĞĞ¾Ğ²Ñ‹Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ v2
        "size": size_metrics,
        "competition": comp_metrics,
        "seasonality": {
            "coefficient": season_coef,
            "current_month": season_details.get('current_month', 0),
            "average_month": season_details.get('average_month', 0),
            "trend": season_details.get('trend', 'unknown'),
            "peak_month": season_details.get('peak_month', ''),
            "dynamics": season_details.get('dynamics', []),
            "yearly_growth": season_details.get('yearly_growth', 0)
        },
        "region_info": region_details,
        
        # Ğ’ĞµÑ€Ğ´Ğ¸ĞºÑ‚ Ğ¸ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ñ‹
        "verdict": verdict,
        "insights": insights,
        
        # ĞšĞ»Ğ°ÑÑ‚ĞµÑ€Ñ‹
        "clusters": clusters,
        
        # Ğ¡Ñ‚Ğ°Ñ€Ñ‹Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ´Ğ»Ñ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
        "metrics": {
            "total_count": total_count,
            "niche_size": size_metrics['size_label'],
            "niche_size_icon": size_metrics['size_icon'],
            "competition": comp_metrics['competition_label'],
            "competition_icon": comp_metrics['competition_icon'],
            "top3_share": comp_metrics['factors'].get('top3_concentration', 0),
            "geo_share": geo_share,
            "mp_share": mp_share,
            "brand_share": comp_metrics['factors'].get('brand_share', 0),
        }
    }


def generate_insights_v2(
    size: Dict, 
    competition: Dict, 
    seasonality: Dict,
    clusters: List[Dict],
    geo_share: float,
    mp_share: float
) -> List[Dict]:
    """Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ğµ Ğ¸Ğ½ÑĞ°Ğ¹Ñ‚Ñ‹ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº"""
    
    insights = []
    
    # 1. Ğ Ğ°Ğ·Ğ¼ĞµÑ€ Ğ½Ğ¸ÑˆĞ¸
    size_text = f"{size['raw_count']:,} Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²/Ğ¼ĞµÑ"
    if size['season_coefficient'] < 0.8:
        size_text += f" (ÑĞµĞ¹Ñ‡Ğ°Ñ Ğ½Ğ¸Ğ·ĞºĞ¸Ğ¹ ÑĞµĞ·Ğ¾Ğ½, Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ğ¾ Ã—{1/size['season_coefficient']:.1f})"
    elif size['season_coefficient'] > 1.2:
        size_text += f" (ÑĞµĞ¹Ñ‡Ğ°Ñ Ğ²Ñ‹ÑĞ¾ĞºĞ¸Ğ¹ ÑĞµĞ·Ğ¾Ğ½)"
        
    insights.append({
        "icon": size['size_icon'],
        "title": f"{size['size_label']} Ğ½Ğ¸ÑˆĞ°",
        "text": size_text,
        "index": size['size_index'],
        "type": "size"
    })
    
    # 2. ĞšĞ¾Ğ½ĞºÑƒÑ€ĞµĞ½Ñ†Ğ¸Ñ
    comp_factors = competition['factors']
    comp_details = []
    if comp_factors.get('top3_concentration', 0) > 40:
        comp_details.append(f"Ñ‚Ğ¾Ğ¿-3 ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ° = {comp_factors['top3_concentration']:.0f}%")
    if comp_factors.get('brand_share', 0) > 10:
        comp_details.append(f"Ğ±Ñ€ĞµĞ½Ğ´Ñ‹ = {comp_factors['brand_share']:.0f}%")
    if comp_factors.get('found_brands'):
        comp_details.append(f"Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹: {', '.join(comp_factors['found_brands'][:5])}")
    
    insights.append({
        "icon": competition['competition_icon'],
        "title": f"ĞšĞ¾Ğ½ĞºÑƒÑ€ĞµĞ½Ñ†Ğ¸Ñ: {competition['competition_label'].lower()}",
        "text": "; ".join(comp_details) if comp_details else "Ğ£Ğ¼ĞµÑ€ĞµĞ½Ğ½Ğ°Ñ ĞºĞ¾Ğ½Ñ†ĞµĞ½Ñ‚Ñ€Ğ°Ñ†Ğ¸Ñ ÑĞ¿Ñ€Ğ¾ÑĞ°",
        "index": competition['competition_index'],
        "type": "competition"
    })
    
    # 3. Ğ¡ĞµĞ·Ğ¾Ğ½Ğ½Ğ¾ÑÑ‚ÑŒ
    trend_labels = {
        "growing": ("ğŸ“ˆ", "Ñ€Ğ°ÑÑ‚Ñ‘Ñ‚"),
        "declining": ("ğŸ“‰", "Ğ¿Ğ°Ğ´Ğ°ĞµÑ‚"),
        "stable": ("â¡ï¸", "ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¹"),
        "unknown": ("â“", "Ğ½ĞµĞ¸Ğ·Ğ²ĞµÑÑ‚ĞµĞ½")
    }
    trend_icon, trend_text = trend_labels.get(seasonality.get('trend', 'unknown'), ("â“", "?"))
    
    season_coef = seasonality.get('coefficient', 1.0)
    if season_coef < 0.7:
        season_text = f"ĞĞ¸Ğ·ĞºĞ¸Ğ¹ ÑĞµĞ·Ğ¾Ğ½ (Ã—{season_coef:.2f} Ğ¾Ñ‚ ÑÑ€ĞµĞ´Ğ½ĞµĞ³Ğ¾). Ğ¢Ñ€ĞµĞ½Ğ´: {trend_text}"
    elif season_coef > 1.3:
        season_text = f"Ğ’Ñ‹ÑĞ¾ĞºĞ¸Ğ¹ ÑĞµĞ·Ğ¾Ğ½ (Ã—{season_coef:.2f} Ğ¾Ñ‚ ÑÑ€ĞµĞ´Ğ½ĞµĞ³Ğ¾). Ğ¢Ñ€ĞµĞ½Ğ´: {trend_text}"
    else:
        season_text = f"ĞĞ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ÑĞµĞ·Ğ¾Ğ½. Ğ¢Ñ€ĞµĞ½Ğ´: {trend_text}"
    
    insights.append({
        "icon": trend_icon,
        "title": "Ğ¡ĞµĞ·Ğ¾Ğ½Ğ½Ğ¾ÑÑ‚ÑŒ",
        "text": season_text,
        "type": "seasonality"
    })
    
    # 4. Ğ¢Ğ¾Ğ¿ Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ
    if clusters:
        top3 = clusters[:3]
        top_names = [f"{c['name']} ({c['share']}%)" for c in top3]
        insights.append({
            "icon": "ğŸ¯",
            "title": "Ğ¢Ğ¾Ğ¿ Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ",
            "text": ", ".join(top_names),
            "type": "clusters"
        })
    
    # 5. Ğ“ĞµĞ¾-Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹
    if geo_share > 5:
        insights.append({
            "icon": "ğŸŒ",
            "title": "Ğ›Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ÑĞ¿Ñ€Ğ¾Ñ",
            "text": f"{geo_share:.1f}% Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ñ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ³Ğ¾Ñ€Ğ¾Ğ´Ğ°. Ğ“ĞµĞ¾Ñ‚Ğ°Ñ€Ğ³ĞµÑ‚Ğ¸Ğ½Ğ³ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²ĞµĞ½.",
            "type": "geo"
        })
    
    # 6. ĞœĞ°Ñ€ĞºĞµÑ‚Ğ¿Ğ»ĞµĞ¹ÑÑ‹
    if mp_share > 2:
        insights.append({
            "icon": "ğŸ›’",
            "title": "ĞœĞ°Ñ€ĞºĞµÑ‚Ğ¿Ğ»ĞµĞ¹ÑÑ‹",
            "text": f"{mp_share:.1f}% Ğ¸Ñ‰ÑƒÑ‚ Ğ½Ğ° WB, Ozon Ğ¸ Ğ´Ñ€. ĞšĞ°Ğ½Ğ°Ğ» Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶ Ğ°ĞºÑ‚ÑƒĞ°Ğ»ĞµĞ½.",
            "type": "marketplace"
        })
    
    return insights


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ¢Ğ•Ğ¡Ğ¢
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    import json
    
    result = analyze_niche_v2("ĞºÑƒĞ¿Ğ¸Ñ‚ÑŒ ĞºÑ€Ğ¾ÑÑĞ¾Ğ²ĞºĞ¸", region=213)
    
    print("=== ĞĞĞĞ›Ğ˜Ğ— ĞĞ˜Ğ¨Ğ˜ v2.0 ===\n")
    print(f"Ğ¤Ñ€Ğ°Ğ·Ğ°: {result.get('phrase')}")
    print(f"Ğ ĞµĞ³Ğ¸Ğ¾Ğ½: {result.get('region')}")
    print(f"Ğ’ÑĞµĞ³Ğ¾ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²: {result.get('total_count', 0):,}")
    print(f"Ğ£Ğ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ñ„Ñ€Ğ°Ğ·: {result.get('total_queries', 0)}")
    print(f"ĞšĞ»Ğ°ÑÑ‚ĞµÑ€Ğ¾Ğ²: {result.get('clusters_count', 0)}")
    
    print(f"\n--- Ğ Ğ°Ğ·Ğ¼ĞµÑ€ Ğ½Ğ¸ÑˆĞ¸ ---")
    size = result.get('size', {})
    print(f"  Ğ˜Ğ½Ğ´ĞµĞºÑ: {size.get('size_index', 0)}/100")
    print(f"  ĞšĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ: {size.get('size_icon', '')} {size.get('size_label', '')}")
    print(f"  ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¾: {size.get('normalized_count', 0):,}")
    
    print(f"\n--- ĞšĞ¾Ğ½ĞºÑƒÑ€ĞµĞ½Ñ†Ğ¸Ñ ---")
    comp = result.get('competition', {})
    print(f"  Ğ˜Ğ½Ğ´ĞµĞºÑ: {comp.get('competition_index', 0)}/100")
    print(f"  ĞšĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ: {comp.get('competition_icon', '')} {comp.get('competition_label', '')}")
    print(f"  Ğ‘Ñ€ĞµĞ½Ğ´Ñ‹: {comp.get('factors', {}).get('found_brands', [])}")
    
    print(f"\n--- Ğ’ĞµÑ€Ğ´Ğ¸ĞºÑ‚ ---")
    verdict = result.get('verdict', {})
    print(f"  {verdict.get('verdict_icon', '')} {verdict.get('verdict_label', '')}")
    print(f"  ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ°: {verdict.get('reason', '')}")
    
    print(f"\n--- Ğ˜Ğ½ÑĞ°Ğ¹Ñ‚Ñ‹ ---")
    for ins in result.get('insights', []):
        print(f"  {ins['icon']} {ins['title']}: {ins['text']}")
